---
title: "Blank RMarkdown file."
author: "Jesse Leigh Patsolic"
output: 
  html_document:
    keep_md: true
---

<!--
### ### INITIAL COMMENTS HERE ###
###
### Jesse Leigh Patsolic 
### 2019
### S.D.G 
#
-->

```{r render, eval=FALSE, echo=FALSE}
require(rmarkdown) 
require(ggplot2) 
rmarkdown::render("aggregateOutput.Rmd") 
system('open aggregateOutput.html')
```

<style type="text/css">
.table {
    width: 40%;
}
tr:hover {background-color:#f5f5f5;}
</style>



```{r cc1}
f <- dir("OutputData", full.names = TRUE)
stats <- vector('list', length = length(f))
```


```{r, eval = FALSE}
for(i in 1:length(f)) {
  fi <- f[i]
  e <- new.env()
  load(fi, e)
  .GlobalEnv$stats[[i]] <- with(e$storeData, 
                      data.frame(dataset = dataset, RandMat = RandMat, 
                                 Scale01 = Scale01, testing.error = testing.error, 
                                 training.error = training.error, OOB.error = OOB.error))
  
  
  rm(e)
}

saveRDS(stats, file = "runStats.rds")
```


## plot results

```{r}
stats <- readRDS('runStats.rds')
dat <- as.data.frame(do.call(rbind, stats))

e.binary <- new.env(parent = emptyenv())

wo <-dat[with(dat, Scale01 == FALSE), ]

md <- merge(w, wo, by = c("dataset", "RandMat"))
tmp <- with(md, sum(testing.error.x <= testing.error.y) / nrow(md))

hist(with(md, testing.error.x - testing.error.y), breaks = 'Fr', xlim = c(-1,1), prob = FALSE,
     main = "testing.error w/ scaling - testing.error w/o scaling")
```

## Which datasets did scaling do better on?
```{r}
tmp <- md[with(md, RandMat == 'RandMatBinary'), ]

ids <- unique(md[with(md, testing.error.x < testing.error.y), 1])

dat <- slb.load.datasets(dataset = as.character(ids[18]), clean.ohe = FALSE)

head(dat[[1]]$X)
```

```{r}
positions <- data.frame(
  x = c(0, 1, 0),
  y = c(0, 1, 1)
)

p <- ggplot(positions, aes(x = x, y = y)) + geom_polygon(alpha = 0.25, fill = 'green')

p + geom_point(data = md, aes(x = testing.error.x, testing.error.y, color = RandMat)) + 
        geom_point() + geom_abline(intercept = 0) + xlab("testing.error w/ scaling") + ylab("testing.error w/o scaling")
```

```{r}
tmp <- 
  with(md, data.frame(diff = testing.error.x - testing.error.y, dataset = dataset))

uid <- as.character(unique(tmp$dataset))

dat <- slb.load.datasets(repositories = "pmlb", task = "classification")

X <- dat[[ which(names(dat) == uid[2]) ]]

```

## Hypothesis tests

Let $X =$ `training error with scaling` and $Y =$ `training error without scaling`.

Let $Z = X - Y$, then $\bar{Z} \sim \mathcal{N}(0,\sigma = \frac{s}{\sqrt{n}})$.

Our hypotheses are as follows:
$H_0: \mu \leq 0$ and $H_A: \mu > 0$


### RandMatBinary

```{r}
tmp <- md[with(md, RandMat == 'RandMatBinary'), ]

sd0 <- 
  sd(with(tmp, testing.error.x - testing.error.y)) / sqrt(nrow(tmp))

zbar <- 
  mean(with(tmp, testing.error.x - testing.error.y))

pnorm(q = zbar, mean = 0, sd = sd0)
```

### RandMatContinuous

```{r}
tmp <- md[with(md, RandMat == 'RandMatContinuous'), ]

sd0 <- sd(with(tmp, testing.error.x - testing.error.y)) / sqrt(nrow(tmp))

zbar <- 
  mean(with(tmp, testing.error.x - testing.error.y))

pnorm(q = zbar, mean = 0, sd = sd0)
```

```{r}
tmp <- md[with(md, RandMat == 'RandMatRF'), ]

sd0 <- sd(with(tmp, testing.error.x - testing.error.y)) / sqrt(nrow(tmp))

zbar <- 
  mean(with(tmp, testing.error.x - testing.error.y))

pnorm(q = zbar, mean = 0, sd = sd0)
```


## Wilcoxon tests

```{r}
tmp <- md[with(md, RandMat == 'RandMatBinary'), ]

with(tmp, 
     wilcox.test(testing.error.x, testing.error.y, alt = "less", paried = TRUE)
     )
```

```{r}
tmp <- md[with(md, RandMat == 'RandMatContinuous'), ]

with(tmp, 
     wilcox.test(testing.error.x, testing.error.y, alt = "less", paried = TRUE)
     )
```

```{r}
tmp <- md[with(md, RandMat == 'RandMatRF'), ]

with(tmp, 
     wilcox.test(testing.error.x, testing.error.y, alt = "less", paried = TRUE)
     )
```



<!--
#   Time:
##  Working status:
### Comments:
####Soli Deo Gloria
--> 

