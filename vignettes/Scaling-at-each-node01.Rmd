---
title: "Scaling at each node: Experiment 01"
author: "Jesse L. Patsolic"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r render, include = FALSE, eval = FALSE, echo = FALSE}
require(rmarkdown)
render("Scaling-at-each-node01.Rmd")
system("open Scaling-at-each-node01.html")
```

```{r setup, include = FALSE}
set.seed(2019)
require(knitr)
require(gridExtra)
require(ggplot2)
require(rerf)
require(data.table)
require(scales)
#options(digits = 20)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  fig.width = 8,
  fig.height = 8,
  dev = 'png',
  dpi = 62
)
```

# Introduction

## Toy dataset

Consider the regions described by the sets

$O = \{(x_1, x_2) | \, x_1 \in (10^{-4}, 10^{-3}), x_2 \in  (10^4, 10^5), x_2 < 10^8 \cdot x_1)\}$

$X = \{(x_1, x_2) | \, x_1 \in (10^{-4}, 10^{-3}), x_2 \in  (10^4, 10^5), x_2 > 10^8 \cdot x_1)\}$

Points in class 0 will be sampled from region $O$ and points in class 1
will be sampled from region $X$.


```{r}
n1 <- 1e3
n2 <- 1e3

rx1 <- c(1e-4, 1e-3)
rx2 <- c(1e4, 1e5)
(m <- diff(rx2) / diff(rx1))

ymxb <- function(x) m * x

xb <- c(1e-4, 1e-3)
yb <- c(1e4, 1e5)

xb  <- c(seq(1e-4, 1e-3, length = 5), 1e-3, 1e-4)
yb  <- c(ymxb(xb[-c(6,7)]), 1e4, 1e4)
yb2  <- c(ymxb(xb[-c(6,7)]), 1e5, 1e5)

set.seed(1234)
x11 <- runif(4*n1, rx1[1], rx1[2])
x12 <- runif(4*n2, rx2[1], rx2[2])

Y1o <- (x12 < (m * x11)) + 1

Y1o.ind <- c(sample(which(Y1o == 1), n1), sample(which(Y1o == 2), n2))

Y1 <- Y1o[Y1o.ind]
X1 <- cbind(x11[Y1o.ind], x12[Y1o.ind])

#plot(X1, col = Y1, pch = '.', xlim = rx1, ylim = rx2)
#curve(ymxb, rx1[1],rx1[2], add = TRUE)

plot(X1, col = Y1, type = 'p', pch = '.', cex = 2, main = "True regions
with sampled points")

polygon(x = xb, y = yb, col= scales::alpha('red', 0.25))
polygon(x = xb, y = yb2, col= scales::alpha('blue', 0.25))
```


```{r, echo = FALSE, include = FALSE}
# Find range of current data
r <- apply(X1, 2, range)

# store scaling factors at this node
scalingFactors <- list(min = r[1, ], diff = (r[2, ] - r[1, ]))

# shift data by the minimum
Xscaled <- sweep(X1, MARGIN = 2, STATS = scalingFactors$min, FUN = "-")

Xscaled <-
  sweep(Xscaled, 2, STATS = scalingFactors$diff, FUN = "/")

plot(Xscaled, col = Y1, pch = '.', main = 'scaled data')
curve(identity, add = TRUE, col = scales::alpha(1, 0.5))
```

## Train some forests

```{r, RerF-setup}
FUN <- RandMatBinary
num.cores <- 1L
paramList <- list(p = 2, d = 3, sparsity = 1, prob = 0.5)
ntrees <- 1L
```


```{r}
seed <- 2

f1 <- RerF(X1, Y1, FUN = FUN, paramList = paramList, scaleAtNode = FALSE, trees = ntrees, max.depth = 2L, store.oob = TRUE, store.impurity = TRUE, num.cores = num.cores, seed = seed)
f1.pred <- Predict(X1, f1)

f1s <- RerF(X1, Y1, FUN = FUN, paramList = paramList, scaleAtNode = TRUE, trees = ntrees, max.depth = 2L, store.oob = TRUE, store.impurity = TRUE, num.cores = num.cores, seed = seed)
f1s.pred <- Predict(X1, f1s)

RcppZiggurat::zsetseed(seed)
f1c <- RerF(X1, Y1, FUN = RandMatContinuous,  paramList = paramList, scaleAtNode = FALSE, trees = ntrees, max.depth = 2L, store.oob = TRUE, store.impurity = TRUE, num.cores = num.cores, seed = seed)
f1c.pred <- Predict(X1, f1c)

RcppZiggurat::zsetseed(seed)
f1cs <- RerF(X1, Y1, FUN = RandMatContinuous,  paramList = paramList, scaleAtNode = TRUE, trees = ntrees, max.depth = 2L, store.oob = TRUE, store.impurity = TRUE, num.cores = num.cores, seed = seed)
f1cs.pred <- Predict(X1, f1cs)
```


### Scaled forest (RandMatBinary)

```{r, echo = FALSE, results = 'asis'}
kable(PrintTree(f1s, 1))
```

#### Confusion matrix

```{r, echo = FALSE, results = 'asis'}
kable(table(f1s.pred, Y1))
```

#### Percent error
```{r}
sum(f1s.pred != Y1) / length(Y1)
```

### Un-scaled forest (RandMatBinary)

```{r, results = 'asis'}
kable(PrintTree(f1, 1))
```

#### Confusion matrix

```{r, echo = FALSE, results = 'asis'}
kable(table(f1.pred, Y1))
```

#### Percent error

```{r}
sum(f1.pred != Y1) / length(Y1)
```

### Un-scaled forest (RandMatContinuous)

```{r, results = 'asis'}
kable(PrintTree(f1c, 1))
```

#### Confusion matrix

```{r, echo = FALSE, results = 'asis'}
kable(table(f1c.pred, Y1))
```


#### Percent error

```{r}
sum(f1c.pred != Y1) / length(Y1)
```

### Scaled forest (RandMatContinuous)

```{r, results = 'asis'}
kable(PrintTree(f1cs, 1))
```

#### Confusion matrix

```{r, echo = FALSE, results = 'asis'}
kable(table(f1cs.pred, Y1))
```


#### Percent error

```{r}
sum(f1cs.pred != Y1) / length(Y1)
```









## Plotting the learned decision boundaries on the projected data

```{r}
cutV <- PrintTree(f1s, 1)$CutV[1]

mins <- apply(X1, 2, min)
diff <- apply(X1, 2, max) - mins

X1s <- sweep(sweep(X1, MARGIN = 2, STATS = mins, "-"), MARGIN = 2, STATS = diff, FUN = "/")

sparseM <- matrix(c(1,-1))
A <- X1s %*% sparseM

par(mfrow = c(1,3))
plot(cbind(A, Y1), col = Y1, pch = 19)
abline(v = cutV)
title("Scaled")

cutV <- PrintTree(f1, 1)$CutV[1]
cutF <- PrintTree(f1, 1)$CutF[[1]][c(2,4)]

sparseM <- matrix(cutF)
A <- X1 %*% sparseM

plot(cbind(A, Y1), col = Y1, pch = 19)
abline(v = cutV)
title("Un-Scaled")

cutV <- PrintTree(f1c, 1)$CutV[1]
cutF <- PrintTree(f1c, 1)$CutF[[1]][c(2,4)]

sparseM <- matrix(cutF)
A <- X1 %*% sparseM

plot(cbind(A, Y1), col = Y1, pch = 19)
abline(v = cutV)
title("Continuous")


#plot(X1, col = Y1, type = 'p', pch = '.', cex = 2, main = "True regions
#with sampled points")
#polygon(x = xb, y = yb, col= scales::alpha('red', 0.25))
#polygon(x = xb, y = yb2, col= scales::alpha('blue', 0.25))
#v1 <- c(1e-4, 1e-3)
#v2 <- c(1e4, 1e5)
#V <- rbind(v1, -v1, v2, -v2)
#v3 <- v1 - v2
#v3 <- v1 - v2
#plot(V)
#arrows(v1[1], v3[1], v1[2], v3[2])
#arrows(v1[1], v2[1], v1[2], v2[2])
```


