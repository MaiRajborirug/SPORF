{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Timeseries Rerf Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from rerf.rerfClassifier import rerfClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths\n",
    "base_dir = Path('/mnt/ssd3/ronan/grasp-and-lift-eeg-detection')\n",
    "load_dir = base_dir / 'processed'\n",
    "\n",
    "# Columns name for labels\n",
    "cols = ['HandStart','FirstDigitTouch',\n",
    "        'BothStartLoadPhase','LiftOff',\n",
    "        'Replace','BothReleased']\n",
    "\n",
    "# Number of subjects\n",
    "subjects = range(1,13)\n",
    "\n",
    "# data path\n",
    "prelag = 500\n",
    "postlag = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_keep_balance(y,block_lengths):\n",
    "    \"\"\"\n",
    "    Sort data and labels into blocks that preserve class balance\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: data matrix\n",
    "    y : 1D class labels\n",
    "    block_lengths : Block sizes to sort X,y into that preserve class balance\n",
    "    \"\"\"\n",
    "    clss,counts = np.unique(y, return_counts=True)\n",
    "    ratios = counts / sum(counts)\n",
    "    class_idxs = [np.where(y==i)[0] for i in clss]\n",
    "\n",
    "    sort_idxs = []\n",
    "    \n",
    "    prior_idxs = np.zeros(len(clss)).astype(int)\n",
    "    for n in block_lengths:\n",
    "        get_idxs = np.rint(n*ratios).astype(int)\n",
    "        for idxs,prior_idx,next_idx in zip(class_idxs,prior_idxs,get_idxs):\n",
    "            sort_idxs.append(idxs[prior_idx:next_idx])\n",
    "        prior_idxs = get_idxs\n",
    "        \n",
    "    sort_idxs = np.hstack(sort_idxs)\n",
    "    \n",
    "    return(sort_idxs)\n",
    "\n",
    "def load_data(data_dir, lags, subjects):\n",
    "    \"\"\"\n",
    "    Loads processed X,y data\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for subject in subjects:\n",
    "        h5 = h5py.File(data_dir / f'subj{subject}_prelag={lags[0]}_postlag={lags[1]}_Xy.hdf5','r')\n",
    "        X.append(h5['X'][:])\n",
    "        y.append(h5['y'][:])\n",
    "        h5.close()\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.concatenate(y)\n",
    "\n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subject(s) concatenated together\n",
    "subjects = [1]\n",
    "X,y = load_data(load_dir, [prelag, postlag], subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_est = 500\n",
    "ncores = 4\n",
    "max_features = int(math.sqrt(X.shape[1])/4)\n",
    "HEIGHT = 32\n",
    "hmax = 6\n",
    "hmin = 1\n",
    "WIDTH = int(X.shape[1] / HEIGHT)\n",
    "wmax = 10\n",
    "wmin = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier(s)\n",
    "names = {\"TORF\":\"red\"}\n",
    "\n",
    "classifiers = [rerfClassifier(\n",
    "                projection_matrix=\"S-RerF\", \n",
    "                max_features=max_features,\n",
    "                n_estimators=n_est,\n",
    "                n_jobs=ncores,\n",
    "                image_height=HEIGHT, \n",
    "                image_width=WIDTH, \n",
    "                patch_height_max=hmax,\n",
    "                patch_height_min=hmin,\n",
    "                patch_width_max=wmax,\n",
    "                patch_width_min=wmin\n",
    "                )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create write file\n",
    "timestamp = datetime.now().strftime('%m-%d-%H:%M')\n",
    "f = open(f'EEG_GridSearchCV_{timestamp}.csv', 'w+')\n",
    "f.write(\"classifier,parameters,mean_test_score,mean_fit_time,mean_score_time\\n\")\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Grid search each classifier and write to file\n",
    "parameters = [{'patch_height_max':np.arange(4,13,2), 'patch_height_min':[1],\n",
    "               'patch_width_max':[50,100,200,400], 'patch_width_min':[25]}]\n",
    "best_classifiers = []\n",
    "\n",
    "for clf,name,parameters in tqdm(zip(classifiers, names, parameters)):\n",
    "    gscv = GridSearchCV(clf, parameters, cv=StratifiedShuffleSplit(n_splits=3, test_size=0.1) ,n_jobs=ncores, refit=False)\n",
    "    gscv.fit(X, y)\n",
    "\n",
    "    results = gscv.cv_results_\n",
    "\n",
    "    result_keys = ['params','mean_test_score',\n",
    "                  'mean_fit_time','mean_score_time']\n",
    "\n",
    "    cv_results = [', '.join([str(results[key][i]) for key in result_keys]) for i in range(len(results['params']))]\n",
    "    for cv_result in cv_results:\n",
    "        f.write(f'{name}, {cv_result}\\n')\n",
    "        f.flush()\n",
    "\n",
    "    print(f'Best {name} parameters:')\n",
    "    print(f'{gscv.best_params_}')\n",
    "    print(f'With score {gscv.best_score_}')\n",
    "\n",
    "    #best_classifiers.append(gscv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs. number of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross-validation train & test splits preserving class percentages\n",
    "# k = 2\n",
    "# test_fraction = 0.1\n",
    "# sss = StratifiedShuffleSplit(n_splits=k, test_size=test_fraction, random_state=0)\n",
    "\n",
    "# # Number of training samples\n",
    "# ns = np.linspace(2,np.log10(math.floor(len(y)*(1-test_fraction))),5)\n",
    "# ns = np.power(10,ns).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train & Test\n",
    "# timestamp = '{%m-%d-%H:%M:%S}'.format(datetime.datetime.now())\n",
    "# f = open(f'EEG_results_{timestamp}.csv', 'w+')\n",
    "# f.write(\"classifier,n,Lhat,trainTime,testTime,iterate\\n\")\n",
    "# f.flush()\n",
    "\n",
    "# runList = [(n, clf, name) for n in ns\\\n",
    "#            for clf,name in zip(classifiers, [name for name in names])]\n",
    "\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "#     print(f'Fold {i}')\n",
    "#     bal_index = sort_keep_balance(y[train_idx],ns)\n",
    "    \n",
    "#     for n, clf, name in tqdm(runList)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = rerfClassifier(n_estimators = n_est, projection_matrix = \"RerF\",\n",
    "#             max_features = 28, n_jobs = ncores)\n",
    "\n",
    "# logpath = Path('/home/rflperry/mf_sims')\n",
    "\n",
    "# logging.basicConfig(filename=logpath / 'fashionmnist_mf_logging.log',\n",
    "#                         format='%(asctime)s:%(levelname)s:%(message)s',\n",
    "#                         level=logging.DEBUG\n",
    "#                         )\n",
    "# logging.info('NEW MF FashionMnist RUN')\n",
    "\n",
    "# for n in ns:\n",
    "#     logging.info(f'Test size: {n}')\n",
    "#     clf.fit(X_train[0:n,::], y_train[0:n])\n",
    "#     yhat_test = clf.predict(X_test)\n",
    "#     logging.info(f'Accuracy {np.mean(y_test == yhat_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_rerf",
   "language": "python",
   "name": "ts_rerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
