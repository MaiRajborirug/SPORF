{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from rerf.rerfClassifier import rerfClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated_samples(nchs, n, cls=0, num_noise_chs=3, i=1):\n",
    "    # The desired mean values of the sample.\n",
    "    mu = np.array([5.0, \n",
    "                    0.0, \n",
    "                    10.0])\n",
    "    \n",
    "    y_noise = np.random.random((num_noise_chs, n))\n",
    "\n",
    "    # The desired covariance matrix.\n",
    "    if cls == 0:\n",
    "        r = np.array([\n",
    "            [  3, -2.75*i, -2.00*i],\n",
    "            [ -2.75*i,  5,  1.50*i],\n",
    "            [ -2.00*i,  1.50*i,  1]\n",
    "        ])\n",
    "    elif cls == 1:\n",
    "        r = np.array([\n",
    "            [  3, 0, 0],\n",
    "            [ 0,  10, 0],\n",
    "            [ 0,  0,  1.5]\n",
    "        ])\n",
    "    \n",
    "    # Generate the random samples.\n",
    "    y = np.random.multivariate_normal(mu, r, size=n).T\n",
    "    \n",
    "    y = np.vstack((y[0,:], y_noise[0,:], y[1,:], \n",
    "                        y_noise[1,:], y[2,:], y_noise[2,:]))\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(cov_factor, ns):\n",
    "    np.random.seed(1234)\n",
    "\n",
    "    # length of data sequence\n",
    "    test_size = 0.5\n",
    "\n",
    "    # simulated data parameters\n",
    "    T = 100\n",
    "    nchs = 6\n",
    "\n",
    "    # initialize data structures for train/test data\n",
    "    X_train, Y_train = np.empty(shape=(0,nchs,T)), np.empty(shape=(0))\n",
    "    X_test, Y_test = np.empty(shape=(0,nchs,T)), np.empty(shape=(0))\n",
    "\n",
    "    # simulate over varying sizes of data sequence\n",
    "    for n in ns:\n",
    "        y = []\n",
    "        X = []\n",
    "\n",
    "        # generate correlated multi-variate time series\n",
    "        for i in range(n):\n",
    "            _x = correlated_samples(nchs, T, cls=0, i=cov_factor)\n",
    "            X.append(_x)\n",
    "            y.append(0)\n",
    "        for i in range(n):\n",
    "            _x = correlated_samples(nchs, T, cls=1, i=cov_factor)\n",
    "            X.append(_x)\n",
    "            y.append(1)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # perform training test split\n",
    "        _X_train, _X_test, _y_train, _y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_size, \n",
    "                                                            random_state=42)\n",
    "        X_train = np.vstack((X_train, _X_train))\n",
    "        Y_train = np.hstack((Y_train, _y_train))\n",
    "        X_test = np.vstack((X_test, _X_test))\n",
    "        Y_test = np.hstack((Y_test, _y_test))\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\"MT-MORF\": \"red\"}\n",
    "\n",
    "ncores=20\n",
    "num_runs=3\n",
    "n_est=100  # number of estimators\n",
    "\n",
    "classifiers = [\n",
    "    rerfClassifier(projection_matrix=\"MT-MORF\",\n",
    "                   max_features='auto',\n",
    "                   n_jobs=ncores,\n",
    "                    n_estimators=n_est,\n",
    "                    oob_score=False,\n",
    "                    random_state=0,\n",
    "                    image_height=nchs,\n",
    "                    image_width=T,\n",
    "                    patch_height_max=3,\n",
    "                    patch_height_min=1,\n",
    "                    patch_width_max=20,\n",
    "                    patch_width_min=5\n",
    "                   )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([50,100,200,400,1000,2000,4000])\n",
    "\n",
    "runList = [(n, clf, run) for n in ns\\\n",
    "                       for clf in zip(classifiers, [key for key in names])\\\n",
    "                       for run in range(num_runs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:00<00:02,  8.29it/s]\u001b[A\n",
      " 14%|█▍        | 3/21 [00:00<00:01,  9.14it/s]\u001b[A\n",
      " 24%|██▍       | 5/21 [00:00<00:01,  9.55it/s]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:00<00:01,  9.56it/s]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:00<00:01,  8.17it/s]\u001b[A\n",
      " 38%|███▊      | 8/21 [00:00<00:01,  7.02it/s]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:01<00:01,  6.18it/s]\u001b[A\n",
      " 48%|████▊     | 10/21 [00:01<00:02,  4.25it/s]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:01<00:02,  3.72it/s]\u001b[A\n",
      " 57%|█████▋    | 12/21 [00:02<00:02,  3.39it/s]\u001b[A\n",
      " 62%|██████▏   | 13/21 [00:03<00:04,  1.82it/s]\u001b[A\n",
      " 67%|██████▋   | 14/21 [00:05<00:06,  1.07it/s]\u001b[A\n",
      " 71%|███████▏  | 15/21 [00:06<00:06,  1.02s/it]\u001b[A\n",
      " 76%|███████▌  | 16/21 [00:09<00:07,  1.60s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [00:12<00:07,  1.98s/it]\u001b[A\n",
      " 86%|████████▌ | 18/21 [00:15<00:06,  2.23s/it]\u001b[A\n",
      " 90%|█████████ | 19/21 [00:21<00:06,  3.49s/it]\u001b[A\n",
      " 95%|█████████▌| 20/21 [00:28<00:04,  4.46s/it]\u001b[A\n",
      "100%|██████████| 21/21 [00:34<00:00,  1.66s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ef3e78234b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m####(\"variable,Lhat,trainTime,testTime,iterate\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{clf[1]}, {cov_factor}, {n}, {lhat:2.9f}, {trainTime:2.9f}, {testTime:2.9f}, {iteration}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# Train each classifier on each dataset size, then test\n",
    "# Prep output file:\n",
    "fname = f'./mt-morf_impulse_experiment_covariances.csv'\n",
    "f = open(fname, 'w+')\n",
    "f.write(\"classifier,covariace, n,Lhat,trainTime,testTime,iterate\\n\")\n",
    "f.flush()\n",
    "    \n",
    "for cov_factor in [1e-5, 0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    X_train, y_train, X_test, y_test = simulate_data(cov_factor)\n",
    "\n",
    "    for n, clf, iteration in tqdm(runList):\n",
    "        # print(clf)\n",
    "        if X_train.ndim == 3:\n",
    "            X_train = X_train.reshape(-1, X_train.shape[-1]).T\n",
    "        if X_test.ndim == 3:\n",
    "            X_test = X_test.reshape(-1, X_test.shape[-1]).T\n",
    "        X = X_train[:n]\n",
    "        y = Y_train[:n]\n",
    "\n",
    "        trainStartTime = time.time()\n",
    "        clf[0].fit(X, y)\n",
    "        trainEndTime = time.time()\n",
    "        trainTime = trainEndTime - trainStartTime\n",
    "\n",
    "        testStartTime = time.time()\n",
    "        out = clf[0].predict(X_test)\n",
    "        testEndTime = time.time()\n",
    "        testTime = testEndTime - testStartTime\n",
    "\n",
    "        lhat = np.mean(np.not_equal(out, Y_test).astype(int))\n",
    "\n",
    "        ####(\"variable,Lhat,trainTime,testTime,iterate\")\n",
    "        f.write(f\"{clf[1]}, {cov_factor}, {n}, {lhat:2.9f}, {trainTime:2.9f}, {testTime:2.9f}, {iteration}\\n\")\n",
    "        f.flush()\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(fname)\n",
    "\n",
    "d1 = pd.DataFrame(columns = ['classifier', 'n', 'Lhat', 'color'])\n",
    "\n",
    "k = 0\n",
    "for ni in np.unique(dat['n']):\n",
    "    for cl in np.unique(dat['classifier']):\n",
    "        tmp = dat[np.logical_and(dat['classifier'] == cl,dat['n'] == ni)][['n', 'Lhat']]\n",
    "        d1.loc[k] = [cl] + list(tmp.mean()) + [names[cl]]\n",
    "        k += 1\n",
    "\n",
    "\n",
    "sns.set(style=\"darkgrid\", rc={'figure.figsize':[12,8], 'figure.dpi': 300})\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "for key in names.keys():\n",
    "    grp = d1[d1['classifier'] == key]\n",
    "    ax = grp.plot(ax=ax, kind='line', x='n', y='Lhat', label=key, \\\n",
    "            c = names[key], alpha =0.65)\n",
    "    #ax.set_yscale('log')\n",
    "\n",
    "plt.legend(loc='best',title='Algorithm')\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.ylabel('Mean Test Error')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "#plt.savefig('./s-rerf_impulse_experiment.pdf',dpi=300,format='pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit53fd3cd604f940d1bf12dc62cb04f92e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
