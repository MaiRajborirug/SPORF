{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit53fd3cd604f940d1bf12dc62cb04f92e",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/home/rflperry/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.mixture.gaussian_mixture module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.mixture. Anything that cannot be imported from sklearn.mixture is now part of the private API.\n  warnings.warn(message, FutureWarning)\n"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, multiprocessing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import rerf\n",
    "from rerf.rerfClassifier import rerfClassifier\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from simulate.load_Xy import load_sbms_Xy\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([10,50,100,200,400,1000,2000])\n",
    "\n",
    "\n",
    "n_train = max(ns)\n",
    "n_test = 10000\n",
    "communities1 = [30,30]\n",
    "communities2 = [20,20,20]\n",
    "p1 = [[0.3,0.1],[0.1,0.3]]\n",
    "p2 = [[0.3,0.1,0.1],[0.1,0.3,0.1],[0.1,0.1,0.3]]\n",
    "X_train,y_train,_ = load_sbms_Xy(int(n_train/2),int(n_train/2),communities1,communities2,p1,p2,ns,seed=1)\n",
    "X_train,y_train,size_dict = load_sbms_Xy(int(n_test/2),int(n_test/2),communities1,communities2,p1,p2,seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-af32a67f0324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m classifiers = [\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "## Setup for run\n",
    "names = {\"Log. Reg\": \"#a6cee3\", \n",
    "         \"Lin. SVM\":\"#1f78b4\", \n",
    "         \"SVM\":\"#b2df8a\", \n",
    "         \"kNN\": \"#33a02c\", \n",
    "         \"RF\":\"#fb9a99\", \n",
    "         \"MLP\":\"#fdbf6f\", \n",
    "         \"RerF\":\"#ff7f00\", \n",
    "         \"MORF\":\"#e31a1c\",\n",
    "         \"CNN\":\"#cab2d6\"}\n",
    "\n",
    "ncores=40\n",
    "num_runs=1\n",
    "n_est=100\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=0, n_jobs=ncores, solver='liblinear'),\n",
    "    LinearSVC(),\n",
    "    SVC(C=1.0, kernel='rbf', gamma='auto',random_state=0),\n",
    "    KNeighborsClassifier(3, n_jobs=ncores),\n",
    "    RandomForestClassifier(n_estimators=n_est, max_features='auto', n_jobs=ncores),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, ), random_state=0, max_iter=1000),\n",
    "    rerfClassifier(n_estimators = n_est, projection_matrix = \"RerF\",\n",
    "                    max_features = 'auto', n_jobs = ncores),\n",
    "    rerfClassifier(projection_matrix=\"Graph\",\n",
    "                   max_features='auto',\n",
    "                   n_jobs=ncores,\n",
    "                    n_estimators=n_est,\n",
    "                    oob_score=False,\n",
    "                    random_state=0,\n",
    "                    image_height=size_dict['height'],\n",
    "                    image_width=size_dict['width'],\n",
    "                    patch_height_max=1,\n",
    "                    patch_height_min=1,\n",
    "                    patch_width_max=5,\n",
    "                    patch_width_min=1\n",
    "                   )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'classifiers' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b52f8892cd46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"MORF\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"#e31a1c\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "classifiers = [classifiers[-1]]\n",
    "names = {\"MORF\":\"#e31a1c\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train each classifier on each dataset size, then test\n",
    "## Prep output file:\n",
    "f = open('s-rerf_impulse_experiment_rerf_1run.csv', 'w+')\n",
    "f.write(\"classifier,n,Lhat,trainTime,testTime,iterate\\n\")\n",
    "f.flush()\n",
    "\n",
    "runList = [(n, clf, run) for n in ns\\\n",
    "                       for clf in zip(classifiers, [key for key in names])\\\n",
    "                       for run in range(num_runs)]\n",
    "\n",
    "for n, clf, iteration in tqdm(runList):\n",
    "        X = X_train[:n]\n",
    "        y = Y_train[:n]\n",
    "\n",
    "        trainStartTime = time.time()\n",
    "        clf[0].fit(X, y)\n",
    "        trainEndTime = time.time()\n",
    "        trainTime = trainEndTime - trainStartTime\n",
    "\n",
    "        testStartTime = time.time()\n",
    "        out = clf[0].predict(X_test)\n",
    "        testEndTime = time.time()\n",
    "        testTime = testEndTime - testStartTime\n",
    "\n",
    "        lhat = np.mean(np.not_equal(out, Y_test).astype(int))\n",
    "\n",
    "\n",
    "        ####(\"variable,Lhat,trainTime,testTime,iterate\")\n",
    "        f.write(f\"{clf[1]}, {n}, {lhat:2.9f}, {trainTime:2.9f}, {testTime:2.9f}, {iteration}\\n\")\n",
    "        f.flush()\n",
    "\n",
    "f.close()"
   ]
  }
 ]
}